File: chunk_to_smooth.py
import json
import logging

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

config_file_path = "config.json"

with open(config_file_path, 'r') as config_file:
    config = json.load(config_file)

input_file_path = config["input_file"]
output_file_path = "book_created/combined_output.json"

chunks = []
chapter_counter = 1

def is_title(line):
    return line.startswith("#") and line.endswith("#\n") and len(line.strip()) > 1

def is_separator(line):
    return line.strip() == "#"

with open(input_file_path, 'r', encoding='utf-8') as input_file:
    line_buffer = []

    for line in input_file:
        if (is_title(line) or is_separator(line)) and line_buffer:
            chunks.append(" ".join(line_buffer))
            line_buffer = []

        if is_title(line):
            chunks.append(f"#TITLE{chapter_counter}")
            chapter_counter += 1
            chunks.append(line.strip("#\n"))
        elif is_separator(line):
            chunks.append("#")
            chunks.append(" ".join(line_buffer))
            line_buffer = []
        else:
            line_buffer.append(line.strip())

    if line_buffer:
        chunks.append(" ".join(line_buffer))

with open(output_file_path, 'w', encoding='utf-8') as output_file:
    json.dump(chunks, output_file)

logging.info(f'JSON file created: {output_file_path}')

with open(config_file_path, 'r') as config_file:
    config_data = json.load(config_file)

config_data["json_file"] = output_file_path

with open(config_file_path, 'w') as config_file:
    json.dump(config_data, config_file)

logging.info(f'Config file updated: {config_file_path}')

File: query_processor_smooth.py
# to continue processing and smoothing text
import json
import logging
import os
from chatbot import process_chatbot_request

# Configure logging settings
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# Load input chunks from a JSON file
def load_input_chunks(input_file):
    with open(input_file, "r", encoding='utf-8') as infile:
        return json.load(infile)

# Write output chunks in a .txt file
def write_output_chunk(chunk, response, output_file):
    with open(output_file, "a", encoding='utf-8') as outfile:
        outfile.write(response)
        outfile.write("\n\n")

# Load configuration from config.json
with open('config.json', 'r') as config_file:
    config = json.load(config_file)

input_file = config["json_file"]
output_file = config["input_file"]
additional_context = config["additional_context"]

# Reinitialize the output file
with open(output_file, "w", encoding='utf-8') as outfile:
    pass

# Load chunks from input file
chunks = load_input_chunks(input_file)

#  lines starting with # are written to the output file but not processed, and lines starting with #TITLE are neither written nor processed.
last_chunk = None
for chunk in chunks:
    if chunk.startswith("#TITLE") or not chunk.strip():  # Skip only lines with #TITLE and blank lines
        continue  # Add this line to skip processing the current chunk
    elif chunk.startswith("#"):  # If the line starts with #
        write_output_chunk(chunk, chunk, output_file)  # Write it to the output file
        continue  # Skip processing the current chunk

    else:
        if last_chunk and last_chunk.startswith("#") and not last_chunk.strip():
            user_input = f'Continua "{last_chunk}" utilizzando questo testo (###{chunk}###) ed aggiungendo spunti interessanti'
        else:
            user_input = f"Parafrasa e scrivi con lo stile di Victor Hugo: ###{chunk}### aggiungi spunti interessanti e se ci sono esercizi scrivili in fondo per punti."
        
        # Use the author_personality variable from the config
        author_personality = config['author_personality']
        max_tokens = config['max_tokens']

        # Send the request to the chatbot and get the response
        response = process_chatbot_request(user_input, max_tokens, author_personality, additional_context)
        write_output_chunk(chunk, response, output_file)
    
    last_chunk = chunk

# Log completion of the task
logging.info(f"Task completed: Paraphrased chunks are saved in '{output_file}'")

